<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Head Tracking</title>
    <style>
        #videoCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        #overlayCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }
    </style>
</head>
<body>
    <video id="videoCanvas" autoplay playsinline></video>
    <canvas id="overlayCanvas"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
    <script>
        async function run() {
            const video = document.getElementById('videoCanvas');
            const overlayCanvas = document.getElementById('overlayCanvas');
            const ctx = overlayCanvas.getContext('2d');

            const model = await tf.loadGraphModel('https://tfhub.dev/mediapipe/tfjs-model/face_landmark_detection/1/default/1');
            navigator.mediaDevices.getUserMedia({ video: true })
                .then(stream => {
                    video.srcObject = stream;
                    video.onloadedmetadata = () => {
                        video.play();
                        detectAndDraw(model, video, ctx);
                    };
                })
                .catch(error => {
                    console.error('Error accessing the camera:', error);
                });
        }

        async function detectAndDraw(model, video, ctx) {
            const predictions = await model.estimateFaces({
                input: video,
                returnTensors: false,
                flipHorizontal: false
            });

            // Clear previous drawings
            ctx.clearRect(0, 0, overlayCanvas.width, overlayCanvas.height);

            // Draw a red dot at the center of each detected face (head)
            if (predictions.length > 0) {
                predictions.forEach(face => {
                    const landmarks = face.scaledMesh;
                    const nose = landmarks[4]; // Assuming the fifth landmark represents the nose
                    ctx.beginPath();
                    ctx.fillStyle = 'red';
                    ctx.arc(nose[0], nose[1], 5, 0, 2 * Math.PI);
                    ctx.fill();
                });
            }

            // Repeat the process
            requestAnimationFrame(() => detectAndDraw(model, video, ctx));
        }

        run();
    </script>
</body>
</html>
